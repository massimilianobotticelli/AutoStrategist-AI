# AutoStrategist-AI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)
[![Databricks](https://img.shields.io/badge/Databricks-Enabled-orange.svg)](https://databricks.com/)

An AI-powered platform for optimizing second-hand car sales, built on Databricks. Features an intelligent chat agent that provides market analysis, repair cost estimation, and professional sales descriptions.

## ğŸ¯ Features

- **ğŸ¤– AI Sales Consultant**: LangChain-based agent that interviews users about their vehicle
- **ğŸ“Š Market Analysis**: Real-time price estimation based on historical sales data
- **ğŸ”§ Repair Cost Estimation**: Automatic deduction calculation for vehicle defects
- **ğŸ“ Sales Copy Generation**: Professional listing descriptions for marketplaces
- **ğŸ’¬ Streamlit Chat Interface**: User-friendly web application
- **ğŸš€ MLflow Integration**: Model tracking, registration, and deployment via Unity Catalog
- **ğŸ“¦ Databricks Apps**: Production-ready deployment as a Databricks App

## ğŸ—ï¸ Architecture

This project uses a modern data & AI architecture on Databricks:

- **Data Pipeline**: Medallion architecture (Bronze â†’ Silver â†’ Gold)
- **AI Agent**: LangChain with specialized tools (Market Analyst, Repair Specialist)
- **LLM**: Databricks Foundation Models (`databricks-gpt-oss-120b`)
- **Model Registry**: MLflow with Unity Catalog integration
- **Deployment**: Databricks Asset Bundles (DABs) + Databricks Apps
- **Compute**: Databricks Connect + Serverless Compute

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11
- Poetry (for dependency management)
- Databricks workspace with:
  - Serverless compute enabled (recommended) OR a running cluster
  - Unity Catalog enabled
  - Personal Access Token
- Kaggle API credentials (for data ingestion)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/massimilianobotticelli/AutoStrategist-AI.git
   cd AutoStrategist-AI
   ```

2. **Install dependencies with Poetry**
   ```bash
   poetry install
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` with your credentials:
   ```env
   # Databricks Configuration (REQUIRED)
   DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
   DATABRICKS_TOKEN=your-databricks-token
   
   # Kaggle API (for data ingestion)
   KAGGLE_USERNAME=your-kaggle-username
   KAGGLE_KEY=your-kaggle-api-key
   ```

4. **Configure Databricks CLI**
   ```bash
   databricks configure --token
   # Enter your Databricks workspace URL and personal access token
   ```

5. **Update Databricks Asset Bundle configuration**
   ```bash
   cp databricks.example.yml databricks.yml
   # Edit databricks.yml and update workspace.host with your Databricks URL
   ```

6. **Deploy the data pipeline**
   ```bash
   databricks bundle validate
   databricks bundle deploy
   databricks bundle run ingest_kaggle_data
   ```

### Running the Application

**Option 1: Local Development (Streamlit)**
```bash
poetry run streamlit run app/app.py
```

**Option 2: Deploy as Databricks App**
```bash
databricks bundle deploy
# The app will be available at your Databricks workspace
```

## ğŸ“ Project Structure

```
AutoStrategist-AI/
â”œâ”€â”€ databricks.yml              # Databricks Asset Bundle configuration
â”œâ”€â”€ databricks.example.yml      # Example DABs template
â”œâ”€â”€ pyproject.toml              # Poetry dependencies & project config
â”œâ”€â”€ deploy.py                   # MLflow model deployment utilities
â”œâ”€â”€ .env.example                # Environment variables template
â”‚
â”œâ”€â”€ app/                        # Databricks App (Streamlit)
â”‚   â”œâ”€â”€ app.py                  # Main Streamlit chat interface
â”‚   â”œâ”€â”€ app.yaml                # Databricks App configuration
â”‚   â””â”€â”€ requirements.txt        # App-specific dependencies
â”‚
â”œâ”€â”€ autostrategist_ai/          # Main Python package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/                 # AI Agent components
â”‚   â”‚   â”œâ”€â”€ workflow.py         # Main agent orchestration
â”‚   â”‚   â”œâ”€â”€ tools.py            # LangChain tools (SQL execution, sub-agents)
â”‚   â”‚   â”œâ”€â”€ prompts.py          # System prompts for all agents
â”‚   â”‚   â””â”€â”€ data_structures.py  # Pydantic models (VehicleData, RepairData)
â”‚   â”‚
â”‚   â””â”€â”€ ingestion/              # Data pipeline scripts
â”‚       â”œâ”€â”€ load_data.py        # Download from Kaggle
â”‚       â”œâ”€â”€ ingest_data.py      # Ingest to Bronze layer
â”‚       â”œâ”€â”€ prepare_data.py     # Transform to Silver layer
â”‚       â”œâ”€â”€ car_models_clean.py # Clean car model names
â”‚       â”œâ”€â”€ enrich_data.py      # Enrich to Gold layer
â”‚       â”œâ”€â”€ reparation_data.py  # Load repair costs data
â”‚       â”œâ”€â”€ reparation.csv      # Repair costs reference data
â”‚       â””â”€â”€ prompts.py          # Prompts for data enrichment
â”‚
â”œâ”€â”€ resources/                  # Databricks Asset Bundle resources
â”‚   â”œâ”€â”€ app.yml                 # Databricks App deployment config
â”‚   â”œâ”€â”€ deploy.yml              # Model deployment job config
â”‚   â””â”€â”€ ingestion.yml           # Data pipeline job definitions
â”‚
â””â”€â”€ development/                # Development notebooks
    â”œâ”€â”€ extract_details_dev.ipynb
    â””â”€â”€ prepare_dev.ipynb
```

## ğŸ¤– Agent Architecture

The AutoStrategist agent uses a **tool-based pattern** with specialized capabilities:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AutoStrategist Supervisor              â”‚
â”‚  (Interviews user, orchestrates, generates output)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Market Analyst     â”‚ â”‚  Repair Specialist  â”‚
    â”‚    (SQL Tool)         â”‚ â”‚     (SQL Tool)      â”‚
    â”‚ (vehicles_enriched)   â”‚ â”‚   (reparations)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Tools

| Tool | Description |
|------|-------------|
| `search_vehicle_database` | Queries historical sales data for market analysis |
| `search_reparation_database` | Looks up repair component costs |

### Data Tables

| Table | Description |
|-------|-------------|
| `workspace.car_sales.vehicles_enriched` | Historical car sales with prices, specs |
| `workspace.car_sales.reparations` | Repair components and costs |

## ğŸš€ Deployment

### Model Deployment with MLflow

The project uses MLflow for model lifecycle management:

```python
# Log and register the model
from deploy import log_experiment_lc, register_model, set_model_alias

# Log experiment
run_id = log_experiment_lc(graph, "experiment_name")

# Register to Unity Catalog
register_model(run_id, "workspace.car_sales.car_sales_workflow_model")

# Set alias for production
set_model_alias("workspace.car_sales.car_sales_workflow_model", "champion")
```

### Databricks Apps Deployment

Deploy the Streamlit app as a Databricks App:

```bash
# Validate and deploy
databricks bundle validate
databricks bundle deploy

# The app configuration is in app/app.yaml
```

## ğŸ› ï¸ Development Workflow

### Working with Databricks Asset Bundles

```bash
# Validate configuration
databricks bundle validate

# Deploy to Databricks
databricks bundle deploy

# Run the data ingestion pipeline
databricks bundle run ingest_kaggle_data

# Run model deployment job
databricks bundle run log_register_deploy
```

### Local Development

```bash
# Run the Streamlit app locally
poetry run streamlit run app/app.py

# The app will connect to your Databricks workspace
# using credentials from .env or databricks CLI config
```

### Code Formatting

```bash
poetry run black autostrategist_ai/
poetry run isort autostrategist_ai/
```

## ğŸ“Š Data Pipeline

The pipeline follows the medallion architecture:

| Stage | Script | Description |
|-------|--------|-------------|
| **Load** | `load_data.py` | Downloads Kaggle Craigslist Cars dataset |
| **Bronze** | `ingest_data.py` | Raw data ingestion |
| **Silver** | `prepare_data.py` | Cleaning & standardization |
| **Clean** | `car_models_clean.py` | Normalize car model names |
| **Gold** | `enrich_data.py` | Enrichment & aggregation |
| **Repairs** | `reparation_data.py` | Load repair cost reference data |

## ğŸ”§ Troubleshooting

### "Cluster id or serverless are required"

Ensure you have serverless compute enabled or specify a cluster. For serverless:
```env
DATABRICKS_SERVERLESS_COMPUTE_ID=auto
```

### Connection Issues

1. Ensure your Databricks workspace is accessible
2. Verify `DATABRICKS_HOST` and `DATABRICKS_TOKEN` are correct
3. Check that your token has not expired
4. For local development, ensure `databricks configure` was run successfully

### Model Loading Issues

If the Streamlit app can't load the model:
1. Verify the model exists in Unity Catalog: `workspace.car_sales.car_sales_workflow_model`
2. Check the "champion" alias is set
3. Ensure your token has permissions to access the model

## ğŸ” Security

- Store credentials in Databricks Secrets for production
- Use `.env` for local development (never commit!)
- Keep `.databrickscfg` secure and never commit to version control
- The app uses Unity Catalog for secure model access

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Databricks](https://databricks.com/) for the lakehouse platform
- [LangChain](https://langchain.com/) for the agent framework
- [MLflow](https://mlflow.org/) for model lifecycle management
- [Streamlit](https://streamlit.io/) for the chat interface
- [Kaggle](https://www.kaggle.com/) for the Craigslist Cars dataset
